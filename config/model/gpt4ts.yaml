name: "gpt4ts"

model:
  _target_: src.models.gpt4ts.Model
  seq_len: ${look_back_window}
  pred_len: ${prediction_window}
  ln: 0 
  patch_size: 1
  stride: 1
  d_ff: 128
  d_model: 64
  enc_in: ${dataset.datamodule.look_back_channel_dim}
  c_out: ${dataset.datamodule.look_back_channel_dim}
  gpt_layers: 6
  embed: 'timeF' # time features encoding, options:[timeF, fixed, learned]
  freq: 'm'


pl_model: 
  _target_: src.models.gpt4ts.GPT4TS
  learning_rate: 0.0024543152601071328
  loss: 'MSE'
  lradj: "type1" # lr * 0.5**(epoch - 1 // 1)
  # lradj: "none"


trainer: 
  max_epochs: 50
  use_early_stopping: False
  patience: 5

data:
  batch_size: 64