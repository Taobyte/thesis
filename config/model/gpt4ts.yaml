model_name: "GPT4TS"

model:
  _target_: src.models.gpt4ts.Model
  seq_len: ${look_back_window}
  pred_len: ${prediction_window}
  is_ln: 
  output_attention: True
  use_norm: True
  geomattn_dropout: 0.5
  alpha: 1 
  kernel_size: 5
  channels: 7
  dec_in: 7
  d_model: 512
  n_heads: 8
  individual: True
  dim: 10
  hyper_num: [50, 20, 10]
  inner_size: 5
  window_size: [4,4]
  CSCM: 'Bottleneck_Construct'
  d_bottleneck: 512
  k: 1
  embed_type: 0 # '0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding'
  embed: 'timeF' # time features encoding, options:[timeF, fixed, learned]
  activation: 'gelu'
  output_attention: True
  wv: "db1"
  factor: 1
  dropout: 0.1
  requires_grad: True # set to true to enable trainable wavelets
  m: 3 # Number of levels for the stationary wavelet transform 
  d_ff: 32 # Dimensionality of the feed forward network



pl_model: 
  _target_: src.models.simpletm.SimpleTM
  learning_rate: 0.001