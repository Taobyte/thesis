# @package _global_

model:
  model:
    activation: gelu
    dropout: 0.0386
    hid_dim: 64
    n_hid_layers: 2
  pl_model:
    learning_rate: 0.003
    weight_decay: 0.0001
