# @package _global_

model:
  model:
    activation: gelu
    dropout: 0.0812
    hid_dim: 64
    n_hid_layers: 3
  pl_model:
    learning_rate: 0.001
    weight_decay: 0.0
