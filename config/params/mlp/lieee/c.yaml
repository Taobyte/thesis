# @package _global_

model:
  model:
    activation: relu
    dropout: 0.0495
    hid_dim: 128
    n_hid_layers: 4
  pl_model:
    learning_rate: 0.001
    weight_decay: 0
