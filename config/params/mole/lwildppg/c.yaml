# @package _global_

model:
  data:
    batch_size: 64
  model:
    dropout: 0.2
    input_dropout: 0.1
    n_regimes: 2
    use_last: false
  pl_model:
    learning_rate: 0.0021
    optimizer_name: adam
    weight_decay: 0.0001
