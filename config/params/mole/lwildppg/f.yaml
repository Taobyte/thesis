# @package _global_

model:
  data:
    batch_size: 64
  model:
    dropout: 0.2
    input_dropout: 0.3
    n_regimes: 4
    use_last: false
  pl_model:
    learning_rate: 0.0062
    optimizer_name: adam
    weight_decay: 0.0005
