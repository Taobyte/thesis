# @package _global_


model:
  pl_model:
    optimizer_name: "adamw"
    learning_rate: 0.0066
    weight_decay: 0.000001
  model:
    n_regimes: 32
    use_last: False 
    dropout: 0.2 
    input_dropout: 0.0
  data:
    batch_size: 256